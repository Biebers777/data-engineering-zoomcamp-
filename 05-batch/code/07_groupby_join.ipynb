{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cec1af",
   "metadata": {},
   "source": [
    "# Video \n",
    "\n",
    "-  5.4.2 - GroupBy in Spark\n",
    "-  [![](https://markdown-videos-api.jorgenkh.no/youtube/9qrDsY_2COo)](https://www.youtube.com/watch?v=9qrDsY_2COo&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05ba62",
   "metadata": {},
   "source": [
    "We've been using local spark clusters with below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4341e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/03/02 00:24:03 WARN Utils: Your hostname, Cinders resolves to a loopback address: 127.0.1.1; using 172.17.156.62 instead (on interface eth0)\n",
      "24/03/02 00:24:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/02 00:24:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "\t.master(\"local[*]\") \\\n",
    "\t.appName('test') \\\n",
    "\t.getOrCreate()\n",
    "\t\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b7af4",
   "metadata": {},
   "source": [
    "## Read parquet `green`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd304aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../../data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243991f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.createOrReplaceTempView('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9506f",
   "metadata": {},
   "source": [
    "### Changed from grouping by monthly to hourly\n",
    "\n",
    "filtered for rows starting from '2020-01-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43764a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289f3ec",
   "metadata": {},
   "source": [
    "```sql\n",
    "ORDER BY\n",
    "    1, 2\n",
    "```\n",
    "\n",
    "removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2aa906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:================================================>        (16 + 3) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-09 17:00:00| 225|             82.46|             5|\n",
      "|2020-01-02 21:00:00|  74| 506.4200000000001|            38|\n",
      "|2020-01-27 13:00:00|  24|            203.57|             7|\n",
      "|2020-01-06 16:00:00|  43|343.68000000000006|            21|\n",
      "|2020-01-05 08:00:00|  55|132.51999999999998|             4|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e00310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('../../data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ea6ef",
   "metadata": {},
   "source": [
    "## Read parquet yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ebb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('../../data/pq/yellow/*/*')\n",
    "df_yellow.createOrReplaceTempView('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5be29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    yellow\n",
    "WHERE\n",
    "    tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabdb7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===================================================>    (21 + 2) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------+\n",
      "|               hour|zone|            amount|number_records|\n",
      "+-------------------+----+------------------+--------------+\n",
      "|2020-01-25 12:00:00| 162| 7347.189999999992|           488|\n",
      "|2020-01-21 22:00:00| 164| 4912.309999999998|           268|\n",
      "|2020-01-24 20:00:00| 186| 7087.639999999995|           398|\n",
      "|2020-01-18 12:00:00| 107| 3927.919999999998|           252|\n",
      "|2020-01-19 13:00:00| 164|3883.5399999999986|           224|\n",
      "+-------------------+----+------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bd9264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('../../data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c26c5b",
   "metadata": {},
   "source": [
    "## Read report revenue\n",
    "\n",
    "we read back the revenue reports into spark dataframe\n",
    "\n",
    "video: 5.4.3 Joins in Spark\n",
    "\n",
    "[![](https://markdown-videos-api.jorgenkh.no/youtube/lu7TrqAWuH4)](https://youtu.be/lu7TrqAWuH4&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5d74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.read.parquet('../../data/report/revenue/green')\n",
    "df_yellow_revenue = spark.read.parquet('../../data/report/revenue/yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35015ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5dbaf",
   "metadata": {},
   "source": [
    "## join green & yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9f34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b9c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                       (0 + 20) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|    yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "|2020-01-01 00:00:00|  65|199.48999999999998|                  10|           409.35|                   19|\n",
      "|2020-01-01 00:00:00|  68|              NULL|                NULL|7825.069999999994|                  396|\n",
      "|2020-01-01 00:00:00|  88|              NULL|                NULL|823.8000000000001|                   36|\n",
      "|2020-01-01 00:00:00|  93|              NULL|                NULL|           210.28|                    3|\n",
      "|2020-01-01 00:00:00| 106|             10.56|                   1|             NULL|                 NULL|\n",
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7297019",
   "metadata": {},
   "source": [
    "## write `df_join` to revenue/report/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10238be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet('../../data/report/revenue/total', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e09bd",
   "metadata": {},
   "source": [
    "## read back parquet from revenue/report/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3af7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('../../data/report/revenue/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2a6680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: timestamp, zone: int, green_amount: double, green_number_records: bigint, yellow_amount: double, yellow_number_records: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b42d3",
   "metadata": {},
   "source": [
    "## read parquet zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb46398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('../../data/zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efae6265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75529eda",
   "metadata": {},
   "source": [
    "## join `df_join` & `df_zones`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3cf98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d802fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                       (0 + 20) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|    yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "|2020-01-01 00:00:00|  65|199.48999999999998|                  10|           409.35|                   19|\n",
      "|2020-01-01 00:00:00|  68|              NULL|                NULL|7825.069999999994|                  396|\n",
      "|2020-01-01 00:00:00|  88|              NULL|                NULL|823.8000000000001|                   36|\n",
      "|2020-01-01 00:00:00|  93|              NULL|                NULL|           210.28|                    3|\n",
      "|2020-01-01 00:00:00| 106|             10.56|                   1|             NULL|                 NULL|\n",
      "+-------------------+----+------------------+--------------------+-----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca93db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e0614ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.drop('LocationID', 'zone').write.parquet('../../data/tmp/revenue-zones', mode=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ca913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
