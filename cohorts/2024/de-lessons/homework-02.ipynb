{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Homework\n",
    "\n",
    "For the homework, we'll be working with the _green_ taxi dataset located here:\n",
    "\n",
    "`https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green`\n",
    "\n",
    "Mage project folders is in PROJECT_NAME=`hmwk-02`, with these folders pushed to github.\n",
    "\n",
    "```\n",
    ".\n",
    "├── data_exporters\n",
    "├── data_loaders\n",
    "├── pipelines\n",
    "├── transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree . -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "The goal will be to construct an ETL pipeline that loads the data, performs some transformations, and writes the data to a database (and Google Cloud!).\n",
    "\n",
    "- Create a new pipeline, call it `green_taxi_etl`\n",
    "- Add a data loader block and use Pandas to read data for the final quarter of 2020 (months `10`, `11`, `12`).\n",
    "  - You can use the same datatypes and date parsing methods shown in the course.\n",
    "  - `BONUS`: load the final three months using a for loop and `pd.concat`\n",
    "- Add a transformer block and perform the following:\n",
    "  - Remove rows where the passenger count is equal to 0 _or_ the trip distance is equal to zero.\n",
    "  - Create a new column `lpep_pickup_date` by converting `lpep_pickup_datetime` to a date.\n",
    "  - Rename columns in Camel Case to Snake Case, e.g. `VendorID` to `vendor_id`.\n",
    "  - Add three assertions:\n",
    "    - `vendor_id` is one of the existing values in the column (currently)\n",
    "    - `passenger_count` is greater than 0\n",
    "    - `trip_distance` is greater than 0\n",
    "- Using a Postgres data exporter (SQL or Python), write the dataset to a table called `green_taxi` in a schema `mage`. Replace the table if it already exists.\n",
    "- Write your data as Parquet files to a bucket in GCP, partioned by `lpep_pickup_date`. Use the `pyarrow` library!\n",
    "- Schedule your pipeline to run daily at 5AM UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "Observe the pattern in the filenames.\n",
    "\n",
    "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-10.csv.gz\n",
    "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-11.csv.gz\n",
    "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-12.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial test for manual ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "taxi_dtypes = {\n",
    "            'VendorID': pd.Int64Dtype(),\n",
    "            'passenger_count': pd.Int64Dtype(),\n",
    "            'trip_distance': float,\n",
    "            'RatecodeID':pd.Int64Dtype(),\n",
    "            'store_and_fwd_flag':str,\n",
    "            'PULocationID':pd.Int64Dtype(),\n",
    "            'DOLocationID':pd.Int64Dtype(),\n",
    "            'payment_type': pd.Int64Dtype(),\n",
    "            'fare_amount': float,\n",
    "            'extra':float,\n",
    "            'mta_tax':float,\n",
    "            'tip_amount':float,\n",
    "            'tolls_amount':float,\n",
    "            'improvement_surcharge':float,\n",
    "            'total_amount':float,\n",
    "            'congestion_surcharge':float\n",
    "        }\n",
    "\n",
    "# native date parsing \n",
    "parse_dates = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']\n",
    "\n",
    "months = [10, 11, 12]\n",
    "year = 2020\n",
    "colour = 'green' # service\n",
    "base_url=\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download\"\n",
    "\n",
    "# Create empty list to store DataFrames\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# manully looping through 10, 11, 12\n",
    "# oct_2020, nov_2020, dec_2020\n",
    "\n",
    "url='https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-12.csv.gz'\n",
    "\n",
    "dec_2020 = pd.read_csv(\n",
    "            url\n",
    "            , sep=','\n",
    "            , compression='gzip'\n",
    "            , dtype=taxi_dtypes\n",
    "            , parse_dates=parse_dates\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime',\n",
       "       'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID',\n",
       "       'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
       "       'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge',\n",
       "       'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83130, 20)\n",
      "(88605, 20)\n",
      "(95120, 20)\n"
     ]
    }
   ],
   "source": [
    "# Run above manually 3x before running this cell\n",
    "print(dec_2020.shape)\n",
    "print(nov_2020.shape)\n",
    "print(oct_2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_2020.shape[0] + nov_2020.shape[0] + oct_2020.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for-loop for ingestion.\n",
    "Succesful code used in [data_loaders load_api block](./hmwk-02/data_loaders/load_api_green_data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "green_tripdata_2020-10.csv.gz\n",
      "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-10.csv.gz\n",
      "Downloaded green_tripdata_2020-10.csv.gz successfully!\n",
      "11\n",
      "green_tripdata_2020-11.csv.gz\n",
      "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-11.csv.gz\n",
      "Downloaded green_tripdata_2020-11.csv.gz successfully!\n",
      "12\n",
      "green_tripdata_2020-12.csv.gz\n",
      "https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-12.csv.gz\n",
      "Downloaded green_tripdata_2020-12.csv.gz successfully!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through months and download data\n",
    "for month in months:\n",
    "    print(month)\n",
    "    \n",
    "    filename = f\"{colour}_tripdata_{year}-{month:02d}.csv.gz\"\n",
    "    print(filename)\n",
    "\n",
    "    url = f\"{base_url}/{colour}/{filename}\"\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      df = pd.read_csv(\n",
    "         url\n",
    "         , sep=','\n",
    "         , compression='gzip'\n",
    "         , dtype=taxi_dtypes\n",
    "         , parse_dates=parse_dates\n",
    "      ) \n",
    "\n",
    "      # Append DataFrame to the list\n",
    "      dataframes.append(df)\n",
    "      print(f\"Downloaded {filename} successfully!\")\n",
    "      \n",
    "    else:\n",
    "      print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192532</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-06 04:37:21</td>\n",
       "      <td>2020-12-06 05:07:23</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>4.02</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237938</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-12-07 07:59:00</td>\n",
       "      <td>2020-12-07 08:34:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>98</td>\n",
       "      <td>140</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>16.11</td>\n",
       "      <td>39.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>6.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>48.36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124061</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-18 12:02:06</td>\n",
       "      <td>2020-11-18 12:13:41</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-05 11:16:56</td>\n",
       "      <td>2020-10-05 11:20:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-03 12:38:50</td>\n",
       "      <td>2020-10-03 13:22:08</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>18.94</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>57.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103309</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-05 20:39:39</td>\n",
       "      <td>2020-11-05 20:45:37</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182544</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-11-30 08:33:00</td>\n",
       "      <td>2020-11-30 09:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>35</td>\n",
       "      <td>140</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15.18</td>\n",
       "      <td>66.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>6.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>76.00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106484</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-07 18:27:51</td>\n",
       "      <td>2020-11-07 18:35:14</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.45</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59285</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-10-06 15:36:00</td>\n",
       "      <td>2020-10-06 15:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>17</td>\n",
       "      <td>62</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.76</td>\n",
       "      <td>16.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.78</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123745</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-18 09:00:07</td>\n",
       "      <td>2020-11-18 09:26:40</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VendorID lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "192532         2  2020-12-06 04:37:21   2020-12-06 05:07:23   \n",
       "237938      <NA>  2020-12-07 07:59:00   2020-12-07 08:34:00   \n",
       "124061         2  2020-11-18 12:02:06   2020-11-18 12:13:41   \n",
       "7205           1  2020-10-05 11:16:56   2020-10-05 11:20:54   \n",
       "4281           2  2020-10-03 12:38:50   2020-10-03 13:22:08   \n",
       "103309         1  2020-11-05 20:39:39   2020-11-05 20:45:37   \n",
       "182544      <NA>  2020-11-30 08:33:00   2020-11-30 09:20:00   \n",
       "106484         2  2020-11-07 18:27:51   2020-11-07 18:35:14   \n",
       "59285       <NA>  2020-10-06 15:36:00   2020-10-06 15:54:00   \n",
       "123745         1  2020-11-18 09:00:07   2020-11-18 09:26:40   \n",
       "\n",
       "       store_and_fwd_flag  RatecodeID  PULocationID  DOLocationID  \\\n",
       "192532                  N           1            82           145   \n",
       "237938                NaN        <NA>            98           140   \n",
       "124061                  N           1           244           239   \n",
       "7205                    N           1             7           226   \n",
       "4281                    N           1            39            83   \n",
       "103309                  N           1            97            97   \n",
       "182544                NaN        <NA>            35           140   \n",
       "106484                  N           1            66            52   \n",
       "59285                 NaN        <NA>            17            62   \n",
       "123745                  N           1           129           255   \n",
       "\n",
       "        passenger_count  trip_distance  fare_amount  extra  mta_tax  \\\n",
       "192532                2           4.02        20.00    0.5      0.5   \n",
       "237938             <NA>          16.11        39.19    0.0      0.0   \n",
       "124061                1           4.81        16.00    0.0      0.5   \n",
       "7205                  1           0.60         5.00    0.0      0.5   \n",
       "4281                  1          18.94        54.00    0.0      0.5   \n",
       "103309                1           0.70         6.00    0.5      0.5   \n",
       "182544             <NA>          15.18        66.83    0.0      0.0   \n",
       "106484                1           1.45         7.00    0.0      0.5   \n",
       "59285              <NA>           1.76        16.73    0.0      0.0   \n",
       "123745                1           5.10        19.50    0.0      0.5   \n",
       "\n",
       "        tip_amount  tolls_amount  ehail_fee  improvement_surcharge  \\\n",
       "192532        0.00          0.00        NaN                    0.3   \n",
       "237938        2.75          6.12        NaN                    0.3   \n",
       "124061        5.86          0.00        NaN                    0.3   \n",
       "7205          0.00          0.00        NaN                    0.3   \n",
       "4281          2.75          0.00        NaN                    0.3   \n",
       "103309        0.00          0.00        NaN                    0.3   \n",
       "182544        2.75          6.12        NaN                    0.3   \n",
       "106484        1.95          0.00        NaN                    0.3   \n",
       "59285         2.75          0.00        NaN                    0.3   \n",
       "123745        4.05          0.00        NaN                    0.3   \n",
       "\n",
       "        total_amount  payment_type  trip_type  congestion_surcharge  \n",
       "192532         21.30             2        1.0                  0.00  \n",
       "237938         48.36          <NA>        NaN                   NaN  \n",
       "124061         25.41             1        1.0                  2.75  \n",
       "7205            5.80             2        1.0                  0.00  \n",
       "4281           57.55             1        1.0                  0.00  \n",
       "103309          7.30             2        1.0                  0.00  \n",
       "182544         76.00          <NA>        NaN                   NaN  \n",
       "106484          9.75             1        1.0                  0.00  \n",
       "59285          19.78          <NA>        NaN                   NaN  \n",
       "123745         24.35             1        1.0                  0.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "## Question 1. Data Loading\n",
    "\n",
    "### Answer 1: `266,855 rows x 20 columns`\n",
    "\n",
    "Once the dataset is loaded, what's the shape of the data?\n",
    "\n",
    "* 266,855 rows x 20 columns\n",
    "* 544,898 rows x 18 columns\n",
    "* 544,898 rows x 20 columns\n",
    "* 133,744 rows x 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266855, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the final DataFrame\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Data Transformation\n",
    "\n",
    "### Answer 2: `139,370 rows`\n",
    "\n",
    "Upon filtering the dataset where the passenger count is equal to 0 _or_ the trip distance is equal to zero, how many rows are left?\n",
    "\n",
    "* 544,897 rows\n",
    "* 266,855 rows\n",
    "* 139,370 rows\n",
    "* 266,856 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266855, 20)\n",
      "Rows with out passengers: 120123\n",
      "Rows with 0 trip_distance: 7362\n",
      "(139370, 21)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def camel_to_snake(name):\n",
    "    # Replace lowercase-uppercase transitions with underscores\n",
    "    name = re.sub(r'(?<=[a-z])(?=[A-Z])', '_', name)\n",
    "    return name.lower()\n",
    "\n",
    "# clean column names, make all lowercase and convert to snake_case\n",
    "print(combined_df.shape)\n",
    "combined_df.columns = combined_df.columns.map(camel_to_snake)\n",
    "\n",
    "# create new column of date dtype for 'lpep_pickup_date' from 'lpep_pickup_datetime'\n",
    "combined_df['lpep_pickup_date'] = combined_df['lpep_pickup_datetime'].dt.date\n",
    "\n",
    "# drop records of rides with no passengers\n",
    "print(f\"Rows with out passengers: {combined_df['passenger_count'].fillna(0).isin([0]).sum() }\")\n",
    "combined_df = combined_df[combined_df['passenger_count'] > 0]\n",
    "\n",
    "# drop records of rides with 0 trip_distance\n",
    "print(f\"Rows with 0 trip_distance: {combined_df['trip_distance'].fillna(0).isin([0]).sum() }\")\n",
    "combined_df = combined_df[combined_df['trip_distance'] > 0]\n",
    "\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Data Transformation\n",
    "\n",
    "### Answer 3: `data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date`\n",
    "\n",
    "Which of the following creates a new column `lpep_pickup_date` by converting `lpep_pickup_datetime` to a date?\n",
    "\n",
    "* data = data['lpep_pickup_datetime'].date\n",
    "* data('lpep_pickup_date') = data['lpep_pickup_datetime'].date\n",
    "* data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date\n",
    "* data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Data Transformation\n",
    "\n",
    "### Answer 4: `1 or 2`\n",
    "\n",
    "What are the existing values of `VendorID` in the dataset?\n",
    "\n",
    "* 1, 2, or 3\n",
    "* 1 or 2\n",
    "* 1, 2, 3, 4\n",
    "* 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[2, 1]\n",
       "Length: 2, dtype: Int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.vendor_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_id\n",
       "2    117408\n",
       "1     21962\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.vendor_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Data Transformation\n",
    "\n",
    "### Answer 5: `4`\n",
    "\n",
    "How many columns need to be renamed to snake case?\n",
    "\n",
    "* 3\n",
    "* 6\n",
    "* 2\n",
    "* 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime',\n",
       "       'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID',\n",
       "       'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
       "       'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge',\n",
       "       'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "camels = ['VendorID', 'RatecodeID', 'PULocationID', 'DOLocationID']\n",
    "print(len(camels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Data Exporting\n",
    "\n",
    "### Answer 6: `96`\n",
    "\n",
    "Once exported, how many partitions (folders) are present in Google Cloud?\n",
    "\n",
    "* 96\n",
    "* 56\n",
    "* 67\n",
    "* 108\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to BigQuery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `sqlalchemy-bigquery 1.9.0` is only compatible with SQLAlchemy versions < 2.0.0. <br>\n",
    "Not worth it to downgrade?\n",
    "[source](https://pypi.org/project/sqlalchemy-bigquery/)\n",
    "\n",
    "[google-cloud-python](https://github.com/googleapis/google-cloud-python/tree/main)\n",
    "\n",
    "[run-google-bigquery-sql-with-vscode](https://developers.lseg.com/en/article-catalog/article/run-google-bigquery-sql-with-vscode)\n",
    "\n",
    "[pandas-gbq alternative to google.cloud](https://pandas-gbq.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project='nyc-rides-ella')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow_cab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        date(tpep_pickup_datetime) as pickup_date, \n",
    "        SUM(passenger_count) as total_passenger_count,\n",
    "        MAX(trip_distance) as max_trip_distance,\n",
    "        COUNT(*) as number_of_trips\n",
    "    FROM nyc-rides-ella.ny_taxi.yellow_cab_data \n",
    "    GROUP BY \n",
    "        pickup_date\n",
    "    ORDER BY number_of_trips DESC\n",
    "    LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "df_yellow = client.query(query).to_dataframe()\n",
    "df_yellow.shape\n",
    "\n",
    "# WORKS!\n",
    "# rows = client.query_and_wait(query)  # Make an API request.\n",
    "\n",
    "# print(\"The query data:\")\n",
    "# for row in rows:\n",
    "#     # Row values can be accessed by field name or index.\n",
    "#     print(\"date={}, number_of_trips={}\".format(row[0], row[\"number_of_trips\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "df_yellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### green_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project='nyc-rides-ella')\n",
    "import pandas as pd\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM nyc-rides-ella.mage.green_taxi\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "df_green = client.query(query).to_dataframe()\n",
    "df_green.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM lpep_pickup_datetime) AS Year,\n",
    "        EXTRACT(MONTH FROM lpep_pickup_datetime) AS Month,\n",
    "        COUNT(*) as number_of_trips\n",
    "    FROM nyc-rides-ella.mage.green_taxi\n",
    "    GROUP BY Year, Month\n",
    "    ORDER BY\n",
    "        number_of_trips DESC\n",
    "\"\"\"\n",
    "df_green = client.query(query).to_dataframe()\n",
    "df_green.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird outliers/wrong-data there (a trip from `2009`!). Need more cleanup before going forward.\n",
    "\n",
    "\n",
    "## Verify all answers from direct BigQuery queries\n",
    "\n",
    "### Qn 1\n",
    "\n",
    "This is only visible from Pipeline  run of `load_data_from_api` DATA LOADER\n",
    "\n",
    "### Qn 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT  *\n",
    "    FROM nyc-rides-ella.mage.green_taxi\n",
    "\"\"\"\n",
    "df_green = client.query(query).to_dataframe()\n",
    "df_green.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other questions are not reliant on SQL querying of the database, after all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
